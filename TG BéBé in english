# How to use Spiec-Easi?

---
titre: "How to use Spiec-Easi?"
autehor: "Paola Fournier" 
date: "21/06/2021"
sortie: htlm_document
---
# How to use Spiec-Easi (Sparse and Compositionally Robust Inference of Microbial Ecological Networks)?

This tutorial is intended for novices who wants to get acquainted with network inference via the Spiec-Easi model (Kurtz et al., 2015). 

Github (: https://github.com/zdk123/SpiecEasi  
doi : https://doi.org/10.1371/journal.pcbi.1004226 

I chose this model because it addresses two major problems of correlation-based models:   

  1)it uses the concept of conditional dependence to avoid the detection of correlated but indirectly connected taxa. Correlation is a pairwise metric and therefore limited in a multivariate framework.
  2)it takes into account the compositionality of the data by applying a "clr" transformation on the input abundance table.
  
## **Some important concepts before embarking on microbial network inference**
### Compositional data
let's speak first about how amplicon sequencing data is generated and why that can be a problem 

**What is a compositional data ?**   
Compositional data is defined as a vector of strictly positive real numbers with an unknown or uninformative total (e.g., sequencing depth) because the abundance of each component carries only relative information (Pawlowsky-Glahn et al., 2015). 

**How are amplicon sequencing data compositional?**
Sequencing machines can only provide reads up to their capacity, and therefore each sample is subjected to an arbitrary constant sum constraint. NGS-derived datasets are therefore compositional in nature. 

**What are the consequences?**
The number of reads per sample is not fully interpretable by itself: the total number of reads assigned to a sample or taxa do not provide any information about the number of DNA molecules in the original samples.   
Only the relative changes can be oberved: samples cannot be directly compared because they have a specific sequencing depth. 
Many statistical methods should not be used because they assume independence between features (e.g., abondance of each taxa in one sample), which is not the case for NGS generated data.   

**Litterature and proposed solutions**
A popular technique for recalculating absolute abundances is to compare the log ratio of counts to a reference species. In this case, the reference species is known to have an approximately stable abundance across populations. These ratios are compared instead of counts directly.      
If such a species is not known or not available, the reference can be replaced by a robust composite measure obtained from various species. One such measure is the geometric mean of all counts in the sample. This method assumes that an aggregate of various species does not change in mass between their original environments. Figure 1 illustrates the application of alr and clr transformation


<img src="https://github.com/paoluxe/How-to-use-SpiecEasi-/blob/5d1ce20694fb1a99d621cc01e3b2f2cb4f884c21/Pictures%20README/log-ratio.PNG">


### Principle of co-occurrence networks    
Co-occurrence networks require as input abundance tables of taxa from multiple samples. When two taxa co-occur or show a similar abundance pattern among multiple samples, a co-occurence is assumed between them. A positive link is shown in green (graph) or a "1" in the adjacency table (see below). Conversely, when these two taxa are mutually exclusive, a co-exclusion is assumed, illustrated by a red link connecting two nodes (graph) or a "-1" in the adjacency table (see below). 
<p align="center">
<img src="https://github.com/paoluxe/How-to-use-SpiecEasi-/blob/ef1049e3acef34d2c039fd7aee9abb8fbc162609/Pictures%20README/Principe%20R%C3%A9seaux%20de%20co-occurrence.PNG" width = "700">
</p>

### How SpiecEasi works (mb method)
Here is described the "mb" method i.e. Meinshausen-Buhlmann neighborhood selection (Meinshausen and Buhlmann, 2006) which is one of the two network inference methods supported by the SpiecEasi function. The "mb" method has shown good results and is fast in comparison with the "glasso" method (Kurtz et al., 2015; Röttjers and Faust, 2018).   

From a table of taxon abundances on multiple samples, it first applies a "clr" transformation to recalculate absolute abundances. The "mb" inference method consists of fitting penalized regressions using each species in turn as the response and all others as predictors.  In this way, the network is inferred from 80% of the samples n times. The model performs these n iterations (inferring the network from a subsample) over a range of values of λ, the parameter that controls the power of the regularization. SpiecEasi thus generates several adjacency tables from the same initial dataset, but from different subsamples, for each lambda value. Through the StARS tool, it selects λ such that the overall stability of the edges across iterations is maximized.The last step is to generate the network with 100% of the data and the optimized λ.

<p align="center">
  <img src="https://github.com/paoluxe/How-to-use-SpiecEasi-/blob/ef1049e3acef34d2c039fd7aee9abb8fbc162609/Pictures%20README/Principe%20SpiecEasi.PNG" width = "800">
</p>

## **I) Downloading the packages**  
SpiecEasi  
```{r eval=FALSE, include=TRUE}
install.packages("devtools")
library(devtools)
install_github("zdk123/SpiecEasi")
```
phyloseq  

```{r eval=FALSE, include=TRUE}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("phyloseq")

```


## **II) Data loading and creation of the phyloseq object**  

SpiecEasi can be used with an OTU abundance matrix containing samples in rows and taxa in columns.
Row names = sample names / column names = taxa names.

A phyloseq object can also be used.

For the uplaod of the data and the creation of the phyloseq object, this tutorial has been creating according to the following link: https://vaulot.github.io/tutorials/Phyloseq_tutorial.html
Form and content of the input matrices : see link above

Import csv data


```{r eval=FALSE, include=TRUE}
## otu_mat = taxon abundance matrix across multiple samples: otu = rows/samples = columns
otu_mat<- read.csv("otu_mat.csv", sep=";", header = T) ; View(otu_mat)

## tax_mat = taxonomy matrix: otu = rows/taxonomy = columns
tax_mat<- read.csv("tax_mat.csv", sep=";", header = T) ; View(tax_mat)

## samples_df = matrix of variables: samples = rows/variables = columns
samples_df <- read.csv("samples_df.csv", sep=";", header = T) ; View(samples_df)
```
The phyloseq objects must have row names

```{r eval=FALSE, include=TRUE}
library(dplyr)
```
otu_mat : the names of the rows become the otu
```{r eval=FALSE, include=TRUE}
otu_mat <- otu_mat %>%
  tibble::column_to_rownames("otu") ## replace "otu" by the name of the column containing the otu/taxons/sp
```
tax_mat : the names of the rows become the otu
```{r eval=FALSE, include=TRUE}
tax_mat <- tax_mat %>% 
  tibble::column_to_rownames("otu")
```
samples_df : the names of the rows become the samples
```{r eval=FALSE, include=TRUE}
samples_df <- samples_df %>% 
  tibble::column_to_rownames("sample") ## replace "sample" by the name of the column containing the samples
```
Transformation of the data.frame into matrices 
```{r eval=FALSE, include=TRUE}
otu_mat <- as.matrix(otu_mat)
tax_mat <- as.matrix(tax_mat)
```
Creation of the phyloseq object
```{r eval=FALSE, include=TRUE}
library(phyloseq)

OTU = otu_table(otu_mat, taxa_are_rows = TRUE)
TAX = tax_table(tax_mat)
samples = sample_data(samples_df)

obj_physeq <- phyloseq(OTU, TAX, samples)
```


## **III )Dataset processing: dataset separation, application of prevalence/abundance filters**
Create groups of samples to be analyzed according to a modality of a variable
```{r eval=FALSE, include=TRUE}
obj_physeq1 <- subset_samples(obj_physeq, nomvariable =="modalite1") ## replace nomvariable and modalite (nomvariable=name of the variable; madalite=name of the modality)
obj_physeq2 <- subset_samples(obj_physeq, nomvariable =="modalite2") ## replace nomvariable and modalite 
```

**Data filtering**
Röttjers and Faust (2018) recommended the application of a prevalence filter on the abundance matrices to avoid the inference of biased associations due to the high number of zeros in the microbial abundance tables and a niche preference effect.

Indeed, in a heterogeneous environment (biotic and abiotic conditions changing between samples) 2 species with growth optima in the same niches will co-occur. The opposite effect will lead to mutual exclusion.

The microbial abundance tables are rich in zeros, but we don't know their significance, is it due to a real absence or an under-sampling?
Correlations/regressions calculated over many matching zeros will be highly significant, even though the taxa involved may vary randomly below the detection limit. 

The filter_taxa function can be used to apply an abundance or prevalence filter or both on the dataset
Here: the taxa are present at least once in 20% of the samples. These choices are completely arbitrary and are given here as an example
We play on the abundance via "sum(x > 0)" and on the prevalence via "(0.2*length(x))".
```{r eval=FALSE, include=TRUE}
obj_physeq1_filtre = filter_taxa(obj_physeq1, function(x) sum(x > 0) > (0.2*length(x)), TRUE)
```
Another way to filter the data that is not arbitrary is to use the MultiCoLA tool. This tool evaluates the impact of different abundance or rarity thresholds on the structure of the resulting dataset.

  Link to the article : https://academic.oup.com/nar/article/38/15/e155/2409766?login=true   
  doi:10.1093/nar/gkq545
   Scripts available here :https://www.mpi-bremen.de/en/Softwares.html#section1550

## **IV)Co-Occurrence Networks**

Obtaining the network: parameter values recommended by Kurtz
To give you an idea of the processing time , a matrix of 100 samples and 400 OTUs --> 20 minutes
an matrix of 100 samples and 1400 OTU --> 40 minutes
The scripts were run on the specific cluster of calculation (Genouest platorm: https://www.genouest.org/.
```{r eval=FALSE, include=TRUE}
library(SpiecEasi)
se = spiec.easi(obj_physeq1_filtre,method = 'mb',
                     lambda.min.ratio = 1e-2,
                     nlambda = 20,
                     icov.select.params = list(rep.num = 50))
```
"Qualitative" adjacent matrix, an interaction between two nodes takes the value of 1,
whatever its nature, positive or negative.
```{r eval=FALSE, include=TRUE}
refit_matrix = as.matrix(getRefit(se))
colnames(refit_matrix) <- rownames(otu_table(obj_physeq))
rownames(refit_matrix) <- rownames(otu_table(obj_physeq))
View(refit_matrix)
```
"Quantitative" adjacent matrix, an interaction between two nodes is weighted by a coefficient
which indicates the strength of the interaction, it is in fact the regression coefficient. The values go from -1 to 1
```{r eval=FALSE, include=TRUE}
optbeta_matrix = as.matrix(getOptBeta(se.data))
colnames(optbeta_matrix) <- rownames(otu_table(obj_physeq))
rownames(optbeta_matrix) <- rownames(otu_table(obj_physeq))
```
To have only the negative links:
```{r eval=FALSE, include=TRUE}
optbeta_matrix_neg <- function (optbeta_matrix){
optbeta_matrix[optbeta_matrix>0]=0 ## set the positive coefficients to 0
optbeta_matrix[optbeta_matrix<0]=1 ## set the negative coefficients to 1 (this is optional: if you want to have them in qualitative)
return(optbeta_matrix)}

optbeta_matrix_neg(optbeta_matrix)
```
To have only the positive links:
```{r eval=FALSE, include=TRUE}
optbeta_matrix_pos <- function (optbeta_matrix){
optbeta_matrix[optbeta_matrix>0]=1 ## set the positive coefficients to 1 (this is optional: if you want to have them in qualitative)
optbeta_matrix[optbeta_matrix<0]=0 ## set the negative coefficients to 0
return(optbeta_matrix)}

optbeta_matrix_pos(optbeta_matrix)
```
Edge stability matrix: an interaction between two nodes is weighted by a stability value
of the edge. The global stability of the edges is computed through the iterations for the optimal lambda (cf SpiecEasi principle).
```{r eval=FALSE, include=TRUE}
optmerge_matrix = as.matrix(getOptMerge(se.data))
colnames(optmerge_matrix) <- rownames(otu_table(obj_physeq))
rownames(optmerge_matrix) <- rownames(otu_table(obj_physeq))
```
 the same edges are supposed to be obtained using refit_matrix and optbeta_matrix, it's just their values that change, these edges are calculated at the end of the procedure with 100% of the samples and the optimal lambda.
 
 
 
optmerge_matrix gives  the stability of the edges through the N repetitions (here 50) for the optimal lambda 
so,  the  number of edges won't be the same as on the two previous matrices. 
 It is possible to look at your matrix only for a stability above a threshold.

For a (brief) explanation of the functions
```{r eval=FALSE, include=TRUE}
?getRefit
```
The three ways I proposed don't necessarily work with a graph inferred by the "glasso" method.


## **V) Calculation of the network metrics (network scale)
from non-quantitative links
```{r eval=FALSE, include=TRUE}
library(igraph)
ecount(refit_matrix) ## number of edges connecting two nodes contained in the network

sum(degree(refit_matrix)) ## sum of the number of edges per node ~ 2* ecount

mean(degree(refit_matrix)) ## average number of edges per node 

It is possible to normalize these previous metrics by the number of nodes present so that they provide independent information of the number of connected nodes: 
#indeed the more nodes the network contains the more likely it is that the number of edges is also high.
# One way to do this is as follows

ecount.norm <- function(refit_matrix){
  noeud <- vcount(refit_matrix)
  edge <- ecount(refit_matrix)
  return(edge/noeud)
}
ecount.norm (refit_matrix)

sum(degree(refit_matrix, normalized=TRUE)) 

mean(degree(refit_matrix, normalized=TRUE))  
#########


connected.node <- function(reseau){ ## depending on the number of nodes with at least one link in the network
  return(length(which(degree(reseau)>=0)))
}
connected.node(refit_matrix) ## number of connected nodes

average_path_length(refit_matrix) ## average of the shortest path length, calculated over all pairs of nodes  
transitivity(refit_matrix, type="globale") ## probability that two nodes respectively linked to the same third node are themselves linked


 edge.density <- function(refit_matrix){ ## function of link density
  noeud <- vcount(refit_matrix)
  edge <- ecount(refit_matrix) 
  combinaisons <- (noeud*(noeud - 1))/2
  return(edge/combinaisons)
}
edge.density(refit_matrix) ## ratio between the sum of the effective links and the sum of the potential links


```

## **VI) Calculation of the node metrics (node scale)** 
